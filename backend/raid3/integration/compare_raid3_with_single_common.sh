# Shared helpers for raid3 comparison and rebuild scripts.
# This file is sourced by compare_raid3_with_single*.sh variants.

WORKDIR="${WORKDIR:-${HOME}/go/raid3storage}"

# Determine script directory so we can locate optional env overrides.
SCRIPT_DIR=${SCRIPT_DIR:-$(cd -- "$(dirname "${BASH_SOURCE[0]}")" && pwd)}

# Resolve rclone config file with priority order:
# 1. RCLONE_CONFIG_CUSTOM (set by --config option in scripts)
# 2. Test-specific config file in WORKDIR (if exists)
# 3. RCLONE_CONFIG environment variable (if set)
# 4. Default rclone config location
TEST_SPECIFIC_CONFIG="${WORKDIR}/rclone_raid3_integration_tests.config"
if [[ -n "${RCLONE_CONFIG_CUSTOM:-}" ]]; then
  RCLONE_CONFIG="${RCLONE_CONFIG_CUSTOM}"
elif [[ -f "${TEST_SPECIFIC_CONFIG}" ]]; then
  RCLONE_CONFIG="${TEST_SPECIFIC_CONFIG}"
elif [[ -n "${RCLONE_CONFIG:-}" ]]; then
  # RCLONE_CONFIG already set (from env or compare_raid3_env.sh)
  :
else
  RCLONE_CONFIG="${HOME}/.config/rclone/rclone.conf"
fi

# Load default environment (required – tracked in git).
if [[ ! -f "${SCRIPT_DIR}/compare_raid3_env.sh" ]]; then
  printf '[%s] ERROR: Missing required env file: %s\n' "${SCRIPT_NAME:-compare_raid3_with_single_common.sh}" "${SCRIPT_DIR}/compare_raid3_env.sh" >&2
  exit 1
fi
# shellcheck source=/dev/null
. "${SCRIPT_DIR}/compare_raid3_env.sh"

# Allow user-specific overrides without touching the tracked file (optional).
if [[ -f "${SCRIPT_DIR}/compare_raid3_env.local.sh" ]]; then
  # shellcheck source=/dev/null
  . "${SCRIPT_DIR}/compare_raid3_env.local.sh"
fi

# Directory layout used by the configured backends. All variables below are
# expected to come from compare_raid3_env.sh (or its local override).
LOCAL_RAID3_DIRS=(
  "${LOCAL_EVEN_DIR}"
  "${LOCAL_ODD_DIR}"
  "${LOCAL_PARITY_DIR}"
)
LOCAL_SINGLE_DIR="${LOCAL_SINGLE_DIR}"
LOCAL_RAID3_REMOTES=(
  "${LOCAL_EVEN_REMOTE}"
  "${LOCAL_ODD_REMOTE}"
  "${LOCAL_PARITY_REMOTE}"
)

MINIO_RAID3_DIRS=(
  "${MINIO_EVEN_DIR}"
  "${MINIO_ODD_DIR}"
  "${MINIO_PARITY_DIR}"
)
MINIO_SINGLE_DIR="${MINIO_SINGLE_DIR}"
MINIO_RAID3_REMOTES=(
  "${MINIO_EVEN_REMOTE}"
  "${MINIO_ODD_REMOTE}"
  "${MINIO_PARITY_REMOTE}"
)
MINIO_S3_PORTS=(
  "${MINIO_EVEN_PORT}"
  "${MINIO_ODD_PORT}"
  "${MINIO_PARITY_PORT}"
  "${MINIO_SINGLE_PORT}"
)

# Directories explicitly allowed for cleanup
ALLOWED_DATA_DIRS=(
  "${LOCAL_RAID3_DIRS[@]}"
  "${LOCAL_SINGLE_DIR}"
  "${MINIO_RAID3_DIRS[@]}"
  "${MINIO_SINGLE_DIR}"
)

# Definition of MinIO containers: name|user|password|s3_port|console_port|data_dir
MINIO_CONTAINERS=(
  "${MINIO_EVEN_NAME}|${MINIO_EVEN_USER:-even}|${MINIO_EVEN_PASS:-evenpass88}|${MINIO_EVEN_PORT}|9004|${MINIO_EVEN_DIR}"
  "${MINIO_ODD_NAME}|${MINIO_ODD_USER:-odd}|${MINIO_ODD_PASS:-oddpass88}|${MINIO_ODD_PORT}|9005|${MINIO_ODD_DIR}"
  "${MINIO_PARITY_NAME}|${MINIO_PARITY_USER:-parity}|${MINIO_PARITY_PASS:-paritypass88}|${MINIO_PARITY_PORT}|9006|${MINIO_PARITY_DIR}"
  "${MINIO_SINGLE_NAME}|${MINIO_SINGLE_USER:-single}|${MINIO_SINGLE_PASS:-singlepass88}|${MINIO_SINGLE_PORT}|9007|${MINIO_SINGLE_DIR}"
)

log_tag() {
  local tag="$1"
  shift
  printf '[%s] %s %s\n' "${SCRIPT_NAME}" "${tag}" "$*"
}

log_info() {
  log_tag "INFO" "$*"
}

log_warn() {
  log_tag "WARN" "$*"
}

log_pass() {
  log_tag "PASS" "$*"
}

log_fail() {
  log_tag "FAIL" "$*"
}

log_note() {
  log_tag "NOTE" "$*"
}

log() {
  log_info "$*"
}

die() {
  printf '[%s] ERROR: %s\n' "${SCRIPT_NAME}" "$*" >&2
  exit 1
}

ensure_workdir() {
  if [[ "${PWD}" != "${WORKDIR}" ]]; then
    die "This script must be run from ${WORKDIR} (current: ${PWD})"
  fi
}

ensure_rclone_config() {
  log_info "config" "Using rclone config: ${RCLONE_CONFIG}"
  [[ -f "${RCLONE_CONFIG}" ]] || die "rclone config not found at ${RCLONE_CONFIG}"
}

create_rclone_config() {
  local config_file="${1:-${TEST_SPECIFIC_CONFIG}}"
  local force="${2:-0}"
  
  if [[ -f "${config_file}" && "${force}" -eq 0 ]]; then
    log_warn "config" "Config file already exists: ${config_file}"
    log_warn "config" "Use --force to overwrite, or specify a different path with --config"
    return 1
  fi
  
  # Ensure directory exists
  local config_dir
  config_dir=$(dirname "${config_file}")
  if [[ ! -d "${config_dir}" ]]; then
    mkdir -p "${config_dir}" || die "Failed to create config directory: ${config_dir}"
  fi
  
  log_info "config" "Creating rclone config file: ${config_file}"
  
  # Generate config file content
  cat > "${config_file}" <<EOF
# rclone configuration file for raid3 integration tests
# Generated by: ${SCRIPT_NAME:-compare_raid3_with_single_common.sh}
# Generated on: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
#
# This config file contains remotes for testing the raid3 backend.
# You can edit this file to customize remote names or paths.
#
# Local storage remotes
[${LOCAL_EVEN_REMOTE}]
type = local
nounc = true

[${LOCAL_ODD_REMOTE}]
type = local
nounc = true

[${LOCAL_PARITY_REMOTE}]
type = local
nounc = true

[${LOCAL_SINGLE_REMOTE}]
type = local
nounc = true

# RAID3 remote using local storage
[localraid3]
type = raid3
even = ${LOCAL_EVEN_REMOTE}:
odd = ${LOCAL_ODD_REMOTE}:
parity = ${LOCAL_PARITY_REMOTE}:

# MinIO S3 remotes
[${MINIO_EVEN_REMOTE}]
type = s3
provider = MinIO
access_key_id = ${MINIO_EVEN_USER:-even}
secret_access_key = ${MINIO_EVEN_PASS:-evenpass88}
endpoint = http://localhost:${MINIO_EVEN_PORT}
force_path_style = true

[${MINIO_ODD_REMOTE}]
type = s3
provider = MinIO
access_key_id = ${MINIO_ODD_USER:-odd}
secret_access_key = ${MINIO_ODD_PASS:-oddpass88}
endpoint = http://localhost:${MINIO_ODD_PORT}
force_path_style = true

[${MINIO_PARITY_REMOTE}]
type = s3
provider = MinIO
access_key_id = ${MINIO_PARITY_USER:-parity}
secret_access_key = ${MINIO_PARITY_PASS:-paritypass88}
endpoint = http://localhost:${MINIO_PARITY_PORT}
force_path_style = true

[${MINIO_SINGLE_REMOTE}]
type = s3
provider = MinIO
access_key_id = ${MINIO_SINGLE_USER:-single}
secret_access_key = ${MINIO_SINGLE_PASS:-singlepass88}
endpoint = http://localhost:${MINIO_SINGLE_PORT}
force_path_style = true

# RAID3 remote using MinIO storage
[minioraid3]
type = raid3
even = ${MINIO_EVEN_REMOTE}:
odd = ${MINIO_ODD_REMOTE}:
parity = ${MINIO_PARITY_REMOTE}:
EOF
  
  log_pass "config" "Config file created successfully: ${config_file}"
  log_note "config" "You can now run integration tests. The config file will be used automatically."
  return 0
}

rclone_cmd() {
  # Use --retries 1 for faster failure in tests (avoid 3 retries causing long delays)
  rclone --config "${RCLONE_CONFIG}" --retries 1 "$@"
}

capture_command() {
  local label="$1"
  shift

  local out_file err_file status
  out_file=$(mktemp "/tmp/${label}.stdout.XXXXXX")
  err_file=$(mktemp "/tmp/${label}.stderr.XXXXXX")

  set +e
  rclone_cmd "$@" >"${out_file}" 2>"${err_file}"
  status=$?
  set -e

  printf '%s|%s|%s\n' "${status}" "${out_file}" "${err_file}"
}

capture_command_timed() {
  local label="$1"
  shift

  local out_file err_file status
  out_file=$(mktemp "/tmp/${label}.stdout.XXXXXX")
  err_file=$(mktemp "/tmp/${label}.stderr.XXXXXX")

  local start_time end_time elapsed
  start_time=$(date +%s.%N)
  
  set +e
  rclone_cmd "$@" >"${out_file}" 2>"${err_file}"
  status=$?
  set -e
  
  end_time=$(date +%s.%N)
  # Force LC_NUMERIC=C to ensure dot as decimal separator
  elapsed=$(LC_NUMERIC=C awk "BEGIN {printf \"%.3f\", ${end_time} - ${start_time}}")

  printf '%s|%s|%s|%s\n' "${status}" "${out_file}" "${err_file}" "${elapsed}"
}

print_if_verbose() {
  local tag="$1"
  local stdout_file="$2"
  local stderr_file="$3"

  if (( VERBOSE )); then
    printf '\n[%s stdout]\n' "${tag}"
    cat "${stdout_file}"
    printf '[%s stderr]\n' "${tag}"
    cat "${stderr_file}"
  fi
}

ensure_directory() {
  local dir="$1"
  if [[ ! -d "${dir}" ]]; then
    mkdir -p "${dir}"
  fi
}

container_exists() {
  local name="$1"
  docker ps -a --format '{{.Names}}' | grep -Fxq "${name}"
}

container_running() {
  local name="$1"
  docker ps --format '{{.Names}}' | grep -Fxq "${name}"
}

wait_for_minio_port() {
  local port="$1"
  local retries=30
  local delay=1
  while (( retries > 0 )); do
    if nc -z localhost "${port}" >/dev/null 2>&1; then
      return 0
    fi
    sleep "${delay}"
    (( retries-- ))
  done
  return 1
}

minio_container_for_backend() {
  local backend="$1"
  case "${backend}" in
    even) echo "minioeven" ;;
    odd) echo "minioodd" ;;
    parity) echo "minioparity" ;;
    *) echo "" ;;
  esac
}

stop_single_minio_container() {
  local backend="$1"
  local name
  name=$(minio_container_for_backend "${backend}")
  [[ -n "${name}" ]] || return
  if container_running "${name}"; then
    log_info "docker" "Stopping container '${name}' for backend '${backend}'."
    docker stop "${name}" >/dev/null
  fi
}

start_single_minio_container() {
  local backend="$1"
  local name
  name=$(minio_container_for_backend "${backend}")
  [[ -n "${name}" ]] || return
  if container_exists "${name}"; then
    log_info "docker" "Starting container '${name}' for backend '${backend}'."
    docker start "${name}" >/dev/null
  else
    # Fallback to launching via start_minio_containers (ensures config).
    log_info "docker" "Container '${name}' missing; launching all MinIO containers."
    start_minio_containers
  fi
}

start_minio_containers() {
  for entry in "${MINIO_CONTAINERS[@]}"; do
    IFS='|' read -r name user pass s3_port console_port data_dir <<<"${entry}"
    ensure_directory "${data_dir}"

    if container_running "${name}"; then
      log "Container '${name}' already running – skipping."
      continue
    fi

    if container_exists "${name}"; then
      log "Starting existing container '${name}'."
      docker start "${name}" >/dev/null
      continue
    fi

    log "Launching container '${name}' (ports ${s3_port}/${console_port})."
    docker run -d \
      --name "${name}" \
      -p "${s3_port}:9000" \
      -p "${console_port}:9001" \
      -e "MINIO_ROOT_USER=${user}" \
      -e "MINIO_ROOT_PASSWORD=${pass}" \
      -v "${data_dir}:/data" \
      quay.io/minio/minio server /data --console-address ":9001" >/dev/null
  done
}

ensure_minio_containers_ready() {
  if [[ "${STORAGE_TYPE}" != "minio" ]]; then
    return 0
  fi

  local entry started=0
  for entry in "${MINIO_CONTAINERS[@]}"; do
    IFS='|' read -r name _ _ _ _ data_dir <<<"${entry}"
    ensure_directory "${data_dir}"
    if container_running "${name}"; then
      log_info "autostart" "Container '${name}' already running."
      continue
    fi
    started=1
    if container_exists "${name}"; then
      log_info "autostart" "Starting container '${name}'."
      docker start "${name}" >/dev/null || return 1
    else
      log_info "autostart" "Container '${name}' missing; launching full MinIO set."
      start_minio_containers
      started=0
      break
    fi
  done

  # Wait for S3 ports to come online
  local idx=0
  for entry in "${MINIO_CONTAINERS[@]}"; do
    IFS='|' read -r name _ _ _ _ _ <<<"${entry}"
    local port="${MINIO_S3_PORTS[idx]}"
    log_info "autostart" "Waiting for ${name} (port ${port})..."
    if ! wait_for_minio_port "${port}"; then
      log_fail "autostart" "Port ${port} for ${name} did not open in time."
      return 1
    fi
    ((idx++))
  done

  if (( started )); then
    log_info "autostart" "MinIO containers are ready."
  else
    log_info "autostart" "All MinIO containers already running."
  fi
  return 0
}

stop_minio_containers() {
  local any_running=0
  for entry in "${MINIO_CONTAINERS[@]}"; do
    IFS='|' read -r name _ <<<"${entry}"
    if container_running "${name}"; then
      log "Stopping container '${name}'."
      docker stop "${name}" >/dev/null
      any_running=1
    else
      log "Container '${name}' not running."
    fi
  done

  if (( ! any_running )); then
    log "No MinIO containers were running."
  fi
}

purge_remote_root() {
  local remote="$1"
  log "Purging remote '${remote}:'"

  local entries=()
  local lsd_output=""
  if lsd_output=$(rclone_cmd lsd "${remote}:" 2>/dev/null | awk '{print $5}' || true); then
    while IFS= read -r entry; do
      [[ -n "${entry}" ]] && entries+=("${entry}")
    done <<<"${lsd_output}"
  fi

  if [[ "${#entries[@]}" -eq 0 ]]; then
    log "  (no top-level directories found on ${remote})"
    rclone_cmd purge "${remote}:" >/dev/null 2>&1 || true
  else
    for entry in "${entries[@]}"; do
      if [[ -n "${entry}" ]]; then
        log "  - purging ${remote}:${entry}"
        rclone_cmd purge "${remote}:${entry}" >/dev/null 2>&1 || true
      fi
    done
  fi
}

verify_directory_empty() {
  local dir="$1"
  if [[ ! -d "${dir}" ]]; then
    return
  fi
  local leftover
  leftover=$(find "${dir}" -mindepth 1 \
    -not -path "${dir}/.DS_Store" \
    -not -path "${dir}/.DS_Store/*" \
    -not -path "${dir}/.minio.sys" \
    -not -path "${dir}/.minio.sys/*" \
    -print -quit 2>/dev/null || true)
  if [[ -n "${leftover}" ]]; then
    log "WARNING: directory '${dir}' is not empty after purge."
  fi
}

remove_leftover_files() {
  local dir="$1"

  local allowed=0
  for candidate in "${ALLOWED_DATA_DIRS[@]}"; do
    if [[ "${dir}" == "${candidate}" ]]; then
      allowed=1
      break
    fi
  done

  if (( ! allowed )); then
    log "Refusing to clean unexpected directory '${dir}' (not in whitelist)."
    return
  fi

  case "${dir}" in
    "${WORKDIR}"/*) ;;
    *)
      log "Refusing to clean directory '${dir}' (outside ${WORKDIR})."
      return
      ;;
  esac

  if [[ ! -d "${dir}" ]]; then
    return
  fi

  find "${dir}" -mindepth 1 \
    -not -path "${dir}/.DS_Store" \
    -not -path "${dir}/.DS_Store/*" \
    -not -path "${dir}/.minio.sys" \
    -not -path "${dir}/.minio.sys/*" \
    -exec rm -rf {} + >/dev/null 2>&1 || true
}

cleanup_raid3_dataset_raw() {
  local dataset_id="$1"
  case "${STORAGE_TYPE}" in
    local)
      local idx dir
      for dir in "${LOCAL_RAID3_DIRS[@]}"; do
        if [[ -d "${dir}/${dataset_id}" ]]; then
          rm -rf "${dir:?}/${dataset_id}"
        fi
      done
      ;;
    minio)
      local remote
      for remote in "${MINIO_RAID3_REMOTES[@]}"; do
        rclone_cmd purge "${remote}:${dataset_id}" >/dev/null 2>&1 || true
      done
      ;;
    *)
      ;;
  esac
}

backend_remote_name() {
  local backend="$1"
  case "${STORAGE_TYPE}" in
    local)
      case "${backend}" in
        even) echo "${LOCAL_RAID3_REMOTES[0]}" ;;
        odd) echo "${LOCAL_RAID3_REMOTES[1]}" ;;
        parity) echo "${LOCAL_RAID3_REMOTES[2]}" ;;
        *) die "Unknown backend '${backend}'" ;;
      esac
      ;;
    minio)
      case "${backend}" in
        even) echo "${MINIO_RAID3_REMOTES[0]}" ;;
        odd) echo "${MINIO_RAID3_REMOTES[1]}" ;;
        parity) echo "${MINIO_RAID3_REMOTES[2]}" ;;
        *) die "Unknown backend '${backend}'" ;;
      esac
      ;;
    *)
      die "Unsupported storage type '${STORAGE_TYPE}'"
      ;;
  esac
}

remote_data_dir() {
  local backend="$1"
  case "${STORAGE_TYPE}" in
    local)
      case "${backend}" in
        even) echo "${LOCAL_RAID3_DIRS[0]}" ;;
        odd) echo "${LOCAL_RAID3_DIRS[1]}" ;;
        parity) echo "${LOCAL_RAID3_DIRS[2]}" ;;
        *) die "Unknown backend '${backend}'" ;;
      esac
      ;;
    minio)
      case "${backend}" in
        even) echo "${MINIO_RAID3_DIRS[0]}" ;;
        odd) echo "${MINIO_RAID3_DIRS[1]}" ;;
        parity) echo "${MINIO_RAID3_DIRS[2]}" ;;
        *) die "Unknown backend '${backend}'" ;;
      esac
      ;;
    *)
      die "Unsupported storage type '${STORAGE_TYPE}'"
      ;;
  esac
}

remove_dataset_from_backend() {
  local backend="$1"
  local dataset_id="$2"
  case "${STORAGE_TYPE}" in
    local)
      local dir
      dir=$(remote_data_dir "${backend}")
      rm -rf "${dir:?}/${dataset_id}"
      ;;
    minio)
      local remote
      remote=$(backend_remote_name "${backend}")
      rclone_cmd purge "${remote}:${dataset_id}" >/dev/null 2>&1 || true
      ;;
    *)
      ;;
  esac
}

object_exists_in_backend() {
  local backend="$1"
  local dataset_id="$2"
  local relative_path="$3"
  case "${STORAGE_TYPE}" in
    local)
      local dir
      dir=$(remote_data_dir "${backend}")
      [[ -f "${dir}/${dataset_id}/${relative_path}" ]]
      ;;
    minio)
      local remote
      remote=$(backend_remote_name "${backend}")
      rclone_cmd lsl "${remote}:${dataset_id}/${relative_path}" >/dev/null 2>&1
      ;;
    *)
      return 1
      ;;
  esac
}

wait_for_object_in_backend() {
  local backend="$1"
  local dataset_id="$2"
  local relative_path="$3"
  local attempts=20
  local delay=1
  while (( attempts > 0 )); do
    if object_exists_in_backend "${backend}" "${dataset_id}" "${relative_path}"; then
      return 0
    fi
    sleep "${delay}"
    ((attempts--))
  done
  return 1
}

create_test_dataset() {
  local label="$1"

  # Dataset layout created by this helper (for both remotes):
  #   ${dataset_id}/file_root.txt              → Root-level file
  #   ${dataset_id}/dirA/file_nested.txt       → Nested file in dirA/
  #   ${dataset_id}/dirB/file_placeholder.txt  → Nested file in dirB/
  #
  # Each test using this dataset can rely on these files. The directories are
  # materialized by uploading files, keeping S3/MinIO semantics happy (no empty dirs).
  local timestamp random_suffix test_id
  timestamp=$(date +%Y%m%d%H%M%S)
  printf -v random_suffix '%04d' $((RANDOM % 10000))
  test_id="cmp-${label}-${timestamp}-${random_suffix}"

  local tmpfile1 tmpfile2
  tmpfile1=$(mktemp) || return 1
  tmpfile2=$(mktemp) || { rm -f "${tmpfile1}"; return 1; }

  printf 'Sample data for %s (root file)\n' "${label}" >"${tmpfile1}"
  printf 'Sample data for %s (nested file)\n' "${label}" >"${tmpfile2}"

  local remote
  for remote in "${RAID3_REMOTE}" "${SINGLE_REMOTE}"; do
    if ! rclone_cmd mkdir "${remote}:${test_id}" >/dev/null; then
      log "Failed to mkdir ${remote}:${test_id}"
      rm -f "${tmpfile1}" "${tmpfile2}"
      return 1
    fi
    if ! rclone_cmd copyto "${tmpfile1}" "${remote}:${test_id}/file_root.txt" >/dev/null; then
      log "Failed to copy root sample file to ${remote}:${test_id}"
      rm -f "${tmpfile1}" "${tmpfile2}"
      return 1
    fi
    if ! rclone_cmd copyto "${tmpfile2}" "${remote}:${test_id}/dirA/file_nested.txt" >/dev/null; then
      log "Failed to copy nested sample file to ${remote}:${test_id}"
      rm -f "${tmpfile1}" "${tmpfile2}"
      return 1
    fi
    if ! rclone_cmd copyto "${tmpfile1}" "${remote}:${test_id}/dirB/file_placeholder.txt" >/dev/null; then
      log "Failed to copy placeholder file to ${remote}:${test_id}/dirB"
      rm -f "${tmpfile1}" "${tmpfile2}"
      return 1
    fi
  done

  rm -f "${tmpfile1}" "${tmpfile2}"
  printf '%s\n' "${test_id}"
}

set_remotes_for_storage_type() {
  case "${STORAGE_TYPE}" in
    local)
      # Allow generic override via RAID3_REMOTE environment variable
      RAID3_REMOTE="${RAID3_REMOTE:-localraid3}"
      SINGLE_REMOTE="${SINGLE_REMOTE:-localsingle}"
      ;;
    minio)
      # Allow generic override via RAID3_REMOTE environment variable
      RAID3_REMOTE="${RAID3_REMOTE:-minioraid3}"
      SINGLE_REMOTE="${SINGLE_REMOTE:-miniosingle}"
      ;;
    *)
      die "Unsupported storage type '${STORAGE_TYPE}'"
      ;;
  esac
}